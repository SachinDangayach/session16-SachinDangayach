{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ***Assignment 16 - Context Managers***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1st Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><i> The files are:\n",
    "\n",
    "- personal_info.csv - personal information such as name, gender, etc. (one row per person)\n",
    "- vehicles.csv - what vehicle people own (one row per person)\n",
    "- employment.csv - where a person is employed (one row per person)\n",
    "- update_status.csv - when the person's data was created and last updated\n",
    "\n",
    "    Each file contains a key, SSN, which uniquely identifies a person. This key is present in all four files.\n",
    "You are guaranteed that the same SSN value is present in every file, and that it only appears once per file.\n",
    "In addition, the files are all sorted by SSN, i.e. the SSN values appear in the same order in each file. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Your first task is to create iterators for each of the four files that contained cleaned up data, of the correct type (e.g. string, int, date, etc), and represented by a named tuple.\n",
    "For now these four iterators are just separate, independent iterators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from datetime import datetime\n",
    "from collections import namedtuple  \n",
    "from collections import Counter\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime_object(date_time):\n",
    "    \"\"\"Convert the datetime string to date time object\"\"\"\n",
    "    datetime_str = date_time\n",
    "    datetime_str = datetime_str[:10]+' '+datetime_str[11:-1]\n",
    "    return(datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_row(row,file_name):\n",
    "    \"\"\"Function to cast the Row into proper data type\"\"\"\n",
    "    if file_name == 'vehicles.csv':\n",
    "        row[3] = int(row[3]) # Year\n",
    "    elif file_name == 'update_status.csv':\n",
    "        row[1] = get_datetime_object(row[1]) # last_update\n",
    "        row[2] = get_datetime_object(row[2]) # last_update\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st Iterator for personal_info.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_personal_info(file_name):\n",
    "    \"\"\"Generator to yield one row at a time from personal_info file as a named tuple\"\"\"\n",
    "    with open(file_name) as file:\n",
    "        dialect = csv.Sniffer().sniff(file.readline(), [',',';'])\n",
    "        file.seek(0)  \n",
    "        rows = csv.reader(file, delimiter=dialect.delimiter, quotechar=dialect.quotechar)\n",
    "        headers = next(rows)\n",
    "        headers = (item.replace(\" \", \"_\") for item in headers)\n",
    "        Personal_Info = namedtuple('Personal_Info', headers) # Create named tuple type\n",
    "        for row in rows:\n",
    "            personal_info = Personal_Info(*row) # Create named tuple type\n",
    "            yield personal_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_details = read_personal_info('personal_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Personal_Info(ssn='100-53-9824', first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(personal_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd Iterator for vehicles.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vehicles(file_name):\n",
    "    \"\"\"Generator to yeild one row at a time from vechicles file as a named tuple\"\"\"\n",
    "    with open(file_name) as file:\n",
    "        dialect = csv.Sniffer().sniff(file.readline(), [',',';'])\n",
    "        file.seek(0)  \n",
    "        rows = csv.reader(file, delimiter=dialect.delimiter, quotechar=dialect.quotechar)\n",
    "        headers = next(rows)\n",
    "        headers = (item.replace(\" \", \"_\") for item in headers)\n",
    "        Vehicles = namedtuple('Vehicles', headers) # Create named tuple type\n",
    "        for row in rows:\n",
    "            row = cast_row(row,file_name) # cast to the data types\n",
    "            vehicles = Vehicles(*row) # Create named tuple type\n",
    "            yield vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_details = read_vehicles('vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vehicles(ssn='100-53-9824', vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(vehicle_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3rd Iterator for employment.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_employment(file_name):\n",
    "    \"\"\"Generator to yeild one row at a time from employment file as a named tuple\"\"\"\n",
    "    with open(file_name) as file:\n",
    "        dialect = csv.Sniffer().sniff(file.readline(), [',',';'])\n",
    "        file.seek(0)  \n",
    "        rows = csv.reader(file, delimiter=dialect.delimiter, quotechar=dialect.quotechar)\n",
    "        headers = next(rows)\n",
    "        headers = (item.replace(\" \", \"_\") for item in headers)\n",
    "        Employment = namedtuple('Employment', headers) # Create named tuple type\n",
    "        for row in rows:\n",
    "            row = cast_row(row,file_name) # cast to the data types\n",
    "            employment_info = Employment(*row) # Create named tuple type\n",
    "            yield employment_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "employment_details = read_employment('employment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Employment(employer='Stiedemann-Bailey', department='Research and Development', employee_id='29-0890771', ssn='100-53-9824')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(employment_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4th Iterator for update_status.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_updated_status(file_name):\n",
    "    \"\"\"Generator to yeild one row at a time from updated_status file as a named tuple\"\"\"\n",
    "    with open(file_name) as file:\n",
    "        dialect = csv.Sniffer().sniff(file.readline(), [',',';'])\n",
    "        file.seek(0)  \n",
    "        rows = csv.reader(file, delimiter=dialect.delimiter, quotechar=dialect.quotechar)\n",
    "        headers = next(rows)\n",
    "        headers = (item.replace(\" \", \"_\") for item in headers)\n",
    "        Status = namedtuple('Status', headers) # Create named tuple type\n",
    "        for row in rows:\n",
    "            row = cast_row(row,file_name) # cast to the data types\n",
    "            status_info = Status(*row) # Create named tuple type\n",
    "            yield status_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "status_details = read_updated_status('update_status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(ssn='100-53-9824', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42), created=datetime.datetime(2016, 1, 24, 21, 19, 30))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(status_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 2\n",
    "<p>\n",
    "Create a single iterable that combines all the columns from all the iterators.\n",
    "The iterable should yield named tuples containing all the columns. Make sure that the SSN's across the files match!\n",
    "All the files are guaranteed to be in SSN sort order, and every SSN is unique, and every SSN appears in every file.\n",
    "Make sure the SSN is not repeated 4 times - one time per row is enough!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entire_information(f_personal_info,f_vehicles_info,f_emp_info,f_status):\n",
    "    \"\"\"\n",
    "    Yield combined information from personal_info, vechiles, employement and updates_status files\n",
    "    ('ssn', 'first_name', 'last_name', 'gender', 'language', 'vehicle_make', 'vehicle_model', \n",
    "    'model_year', 'employer', 'department', 'employee_id', 'last_updated', 'created')\n",
    "    \"\"\"\n",
    "    file_list = [f_personal_info,f_vehicles_info,f_emp_info,f_status]\n",
    "    \n",
    "    # Get header Info\n",
    "    \n",
    "    final_header=[]\n",
    "    for file in file_list:\n",
    "        with open(file) as f:\n",
    "            dialect = csv.Sniffer().sniff(f.readline(), [',',';'])\n",
    "            f.seek(0)  \n",
    "            rows = csv.reader(f, delimiter=dialect.delimiter, quotechar=dialect.quotechar)\n",
    "            headers = next(rows)\n",
    "            if file != 'personal_info.csv':\n",
    "                headers = [item.replace(\" \", \"_\") for item in headers]\n",
    "                headers.remove('ssn')\n",
    "                final_header += headers # only one SSN\n",
    "            else:\n",
    "                headers = [item.replace(\" \", \"_\") for item in headers]\n",
    "                final_header = headers\n",
    "    Total_Info = namedtuple('Total_Info', final_header) # Create named tuple type\n",
    "    \n",
    "    # Get information\n",
    "    per_info = read_personal_info(file_list[0])\n",
    "    vech_info = read_vehicles(file_list[1])\n",
    "    emp_info = read_employment(file_list[2])\n",
    "    status_info = read_updated_status(file_list[3])\n",
    "    \n",
    "    for  i in per_info: # Considering all files are of same length, iterate over \n",
    "        info = next(per_info) + next(vech_info)[1:] + next(emp_info)[0:-1] + next(status_info)[1:] \n",
    "        total_info = Total_Info(*info)\n",
    "\n",
    "        yield total_info\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = entire_information('personal_info.csv','vehicles.csv','employment.csv','update_status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 3\n",
    "<p>\n",
    "Next, you want to identify any stale records, where stale simply means the record has not been updated since 3/1/2017 (e.g. last update date < 3/1/2017). Create an iterator that only contains current records (i.e. not stale) based on the last_updated field from the status_update file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latest_information(f_personal_info,f_vehicles_info,f_emp_info,f_status):\n",
    "    \"\"\"\n",
    "    Yield combined information latest from personal_info, vechiles, employement and updates_status files\n",
    "    ('ssn', 'first_name', 'last_name', 'gender', 'language', 'vehicle_make', 'vehicle_model', \n",
    "    'model_year', 'employer', 'department', 'employee_id', 'last_updated', 'created')\n",
    "    \"\"\"\n",
    "    file_list = [f_personal_info,f_vehicles_info,f_emp_info,f_status]\n",
    "    \n",
    "    # Get header Info\n",
    "    \n",
    "    final_header=[]\n",
    "    for file in file_list:\n",
    "        with open(file) as f:\n",
    "            dialect = csv.Sniffer().sniff(f.readline(), [',',';'])\n",
    "            f.seek(0)  \n",
    "            rows = csv.reader(f, delimiter=dialect.delimiter, quotechar=dialect.quotechar)\n",
    "            headers = next(rows)\n",
    "            if file != 'personal_info.csv':\n",
    "                headers = [item.replace(\" \", \"_\") for item in headers]\n",
    "                headers.remove('ssn')\n",
    "                final_header += headers # only one SSN\n",
    "            else:\n",
    "                headers = [item.replace(\" \", \"_\") for item in headers]\n",
    "                final_header = headers\n",
    "    Total_Info = namedtuple('Total_Info', final_header) # Create named tuple type\n",
    "    \n",
    "    # Get information\n",
    "    per_info = read_personal_info(file_list[0])\n",
    "    vech_info = read_vehicles(file_list[1])\n",
    "    emp_info = read_employment(file_list[2])\n",
    "    status_info = read_updated_status(file_list[3])\n",
    "    \n",
    "    for  i in per_info: # Considering all files are of same length, iterate over \n",
    "        info = next(per_info) + next(vech_info)[1:] + next(emp_info)[0:-1] + next(status_info)[1:] \n",
    "        total_info = Total_Info(*info)\n",
    "        if total_info.last_updated.date() > datetime.strptime('3/1/2017', '%m/%d/%Y').date(): # yield only current records\n",
    "            yield total_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_info = latest_information('personal_info.csv','vehicles.csv','employment.csv','update_status.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rec = list(latest_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2017, 10, 7)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_rec[0].last_updated.date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 4\n",
    "<p>\n",
    "Find the largest group of car makes for each gender.\n",
    "Possibly more than one such group per gender exists (equal sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def largest_group(f_personal_info,f_vehicles_info,f_emp_info,f_status,gender):\n",
    "    \"\"\"\n",
    "    Get the files and the gender type as input and return the largest groups for gender\n",
    "    \"\"\"\n",
    "    \n",
    "    total_info = entire_information(f_personal_info,f_vehicles_info,f_emp_info,f_status)\n",
    "    info_list = (row.vehicle_make for row in total_info if row.gender == gender)\n",
    "    car_makers = Counter(info_list)\n",
    "    \n",
    "    x = [v for v in car_makers.values()]\n",
    "   \n",
    "    highest_value = max(x)\n",
    "    top_car_maker = [k for k,v in car_makers.items() if v == highest_value]\n",
    "          \n",
    "    return top_car_maker\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_car_makers_male = largest_group('personal_info.csv','vehicles.csv','employment.csv','update_status.csv','Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ford']"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_car_makers_male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_car_makers_female = largest_group('personal_info.csv','vehicles.csv','employment.csv','update_status.csv','Female')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ford']"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest_car_makers_female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
